{
 "metadata": {
  "kernelspec": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "name": "",
  "signature": "sha256:5a8de011c8bd99408c7f772932bf8b5521a01822ae1f2ffd16dd04618a7a1c8b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# An Introduction to Plotting and Data Analysis in Python Workshop 2\n",
      "[Clyde Fare](mailto://c.fare12@imperial.ac.uk) and [Jo\u00e3o Pedro Malhado](mailto://malhado@imperial.ac.uk), Imperial College London. \n",
      "\n",
      "The notebook is licensed under a [Creative Commons Attribution 3.0 (CC-by) license](http://creativecommons.org/licenses/by/3.0/us)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Overview\n",
      "--------\n",
      "During this workshop we will recap what we covered in workshop then build on it covering importing of modules to extend the functionality we have access to and reading and writing of data and plots. We will then learn to fit data and use basic statistics to characterise how good our fit is.\n",
      "\n",
      "This is an interactive tutorial - as you go through it any time you see something that looks like this:\n",
      "\n",
      "    a = \"Hello\"\n",
      "   \n",
      "that's followed by an empty *code cell* (a light grey rectangle with a label like *\"In[ ]\"*), you should \n",
      "type the expression in the code cell, hit Shift+Return to *execute* it, and note the output.\n",
      "\n",
      "Limit copying and pasting to cells requiring more than 5 lines! You'll learn the concepts better if you type them out yourself.\n",
      "\n",
      "Warning periodically save your work by pressing the save icon above (We'll cover the other icons later but if you want to know what they are now hover your cursor over them)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Recap from workshop 1"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Notebook"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are working inside an interactive Python Notebook. It is composed of code cells where Python code can be executed and non code cells, where descriptive material can be placed.\n",
      "\n",
      "The icons at the top of the page allow us to save the page, add new cells, cut, copy and paste cells, move cells up or down, execute the highlighted cell, halt and reset the current python kernel.\n",
      "\n",
      "We can convert a highlighted cell to a different type of cell using the dropdown menu to the immediate right of the icons.\n",
      "\n",
      "We can execute a code cell/render a markdown cell with Shift+Return.\n",
      "\n",
      "If we want to have direct access to the plotting and numerical functions and include our plots directly in the notebook we need to execute\n",
      "\n",
      "    %pylab inline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To help us visualize some of the data we will add another command that sets how many lines is to display variables\n",
      "\n",
      "    set_printoptions(linewidth=120)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "set_printoptions(linewidth=120)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Variables"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Variables, allow us to refer to data objects with names:\n",
      "    \n",
      "    x=3\n",
      "    y=array([1,2,3])\n",
      "    z=x*y\n",
      "    z"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Arrays"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Arrays are collections of numbers, that we can operate on collectively and are the containers for our data. There are special commands **linspace** and **arange** for creating arrays.\n",
      "\n",
      "**linspace** creates arrays of equally spaced numbers where we specify the initial value, the final value and how many numbers we want inbetween\n",
      "\n",
      "    linspace(-pi, pi, 10)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**arange** creates arrays of equally spaced numbers where we specify the initial value, a stop value (that will not be included), and the interval size:\n",
      "    \n",
      "    arange(0, 10, 3)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And we can refer to elements of the data in an array by using square brackets and the index of the element we want. Remembering the the first element corresponds to index zero.\n",
      "\n",
      "    arange(0,10,1)[0]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    arange(0,10,1)[5]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also refer to slices of the data using a syntax similar to arange where a colon is used in place of the comma.\n",
      "\n",
      "    my_array = arange(0,10,1)\n",
      "    my_array[0:10:3]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus the above alice takes the zeroth (first) element of my_array and then every 3rd element up to but not including 10.\n",
      "\n",
      "If the first index is omitted, it we start at the zeroth index.\n",
      "If the second index is omitted we move up to but not including the N+1th element\n",
      "If the third index is omitted the step size is 1 i.e we include all elements between the first index and the second index - 1\n",
      "\n",
      "Thus\n",
      "    \n",
      "    my_array[::]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Arrays can be multidimensional\n",
      "\n",
      "    my_2d_array = array([[0, 3, 6, 9], [1, 4, 7, 10], [2, 5, 8, 11], [3, 6, 9, 12]])\n",
      "    my_2d_array"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Where indices now refer to the indidual rows:\n",
      "    \n",
      "    my_2d_array[1]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can apply the same indexing mechanism as we did for 1d array except we use a comma to seperate the indexing that refers to the rows and the indexing that refers to the columns:\n",
      "    \n",
      "    my_2d_array[1:4:2,0:3:2]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which is summarised by the following diagram:\n",
      "\n",
      "<img src=numpy_indexing.png></img>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can perform mathematical operations on arrays, which performs the operation on all elements of the array\n",
      "\n",
      "    sin(my_array)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Plots"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can plot using the **plot** and **scatter** commands and display using the **show** commands\n",
      "\n",
      "    plot(arange(10), arange(10)**2, label='$x^2$')\n",
      "    scatter(arange(10), arange(10)**3, label='$x^3$' )\n",
      "    title('My reminder plot')\n",
      "    xlabel('x')\n",
      "    ylabel('y')\n",
      "    legend()\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are many options\n",
      "\n",
      "    age= arange(10)\n",
      "    p_human = age**2\n",
      "    p_badger = age**3\n",
      "\n",
      "    plot(age, p_human, linewidth=2.5, linestyle=\"--\", label='Humans')\n",
      "    scatter(age, p_badger, marker='^', color='red', label='Badgers' )\n",
      "    title('My reminder plot')\n",
      "    xlabel('Age')\n",
      "    ylabel('Power')\n",
      "    legend()\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Going further"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are many occasions where we want to plot data on a logarthimic scale. To illustrate we will load some radioactivity data. Inside our data file are the half lives for some radioactive elements and their atomic numbers. If we load the data and simply plot atomic number versus half life. What we see is not very informative:\n",
      "\n",
      "    r_data = loadtxt('radioactivity_data.csv', delimiter=',')\n",
      "    atomic_nos = r_data[:,0]\n",
      "    half_lives = r_data[:,1]\n",
      "    plot(atomic_nos, half_lives)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we take a look at the half lives we can see why:\n",
      "    \n",
      "    half_lives"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that they range from $10^{-3}$ for Ununoctium to $10^{26}$ seconds for Bismuth - 29 orders of magnitude! Because of this guargantuan range of values plotting the raw data reveals almost nothing. The plot is dominated by the half life of Bismuth and none of the other variation is visible.\n",
      "\n",
      "If we scale the y-axis so that it is logarithmic i,e the units are orders of magnitude then we should have a much better way to visualize the data. We can use the **xscale** and **yscale** functions to do this.\n",
      "\n",
      "    figure(figsize=[12,8])\n",
      "    yscale('log')\n",
      "    plot(atomic_nos, half_lives, marker='o')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which allows us a much better visualization of the data.\n",
      "\n",
      "The above is equivalent to\n",
      "\n",
      "    figure(figsize=[12,8])\n",
      "    plot(atomic_nos, log(half_lives), marker='o')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A plot using logarithmic scaling for one axis and normal linear scaling for another is known as a semi-log plot. It is also possible to create a log-log plot by scaling both axis. This can be useful to pull out linear relationships in otherwise non-linear data. We will see an example of this in workshop 3."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Reading and Writing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The most common use case you will have when plotting data is plotting data that has been generated else where. That means you need a way to load data from somewhere into a notebook.\n",
      "\n",
      "There are severeal ways of doing this, the simplest is **loadtxt**\n",
      "\n",
      "This loads data from a text files, provided the data layed out in a regular format. If you take a look at the file [data.txt](./data.txt) which is in the same directory as this notebook. You will see each lines contains numbers separated by spaces.\n",
      "\n",
      "loadtxt will load this data into an array for us via:\n",
      "\n",
      "    our_data = loadtxt(\"data.txt\")"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    our_data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We could load a text file seperated by commas like [data2.txt](./data2.csv) via:\n",
      "    \n",
      "    loadtxt(\"data2.txt\", delimiter=',')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to loading data from files, if we have arrays of data that we want to save to file. We can use the opposite command **savetxt**. This works analagously to loadtxt thus\n",
      "    \n",
      "    savetxt('my_data_file.txt', our_data)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Creates the file my_data_file.txt, with the data values separated by spaces.\n",
      "\n",
      "If we wanted data separated by commas we would use:\n",
      "    \n",
      "    savetxt('my_data_file2.txt', our_data, delimiter=',')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take a look at the two files you've just produced: [my_data_file.txt](./my_data_file.txt) and [my_data_file2.txt](./my_data_file2.txt)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Basic statistics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets load up a data set and plot a histogram of the data\n",
      "\n",
      "    d=loadtxt('d1.txt')\n",
      "    hist(d)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Histograms tell us how many many data points there are in a particular range of the data. By default the hist command creates 10 bins, equally spaced between the lowest value in the data set and the highest value in the dataset."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use the functions **min** and **max** to find the largest and smallest values in an array.\n",
      "\n",
      "    min(d)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    max(d)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Armed with these values we can check our histogram makes sense. We said before there were 10 bins by default, now that we know the maximum and minimum values we can see that the bin size must be:\n",
      "    \n",
      "    ( max(d) - min(d) )/10"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(Note we had to use brackets because we want the subtraction to occur before the division instead of)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The width of each bin is about 0.75 and we start at about -3.66 and end at about 3.8. Look at the about histogram and make sure that this makes sense - where do you expect the third bin from left to start?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can change the number of bins using the the bin keyword:\n",
      "    \n",
      "    hist(d, bins=20)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are many options to customise histograms, we won't go through them all. But this is a good point to demonstrate a way to use the built in help system. We can automatically get more information on a particular function by typing the function followed by a question mark:\n",
      "    \n",
      "    hist?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This pops up a footer window that has lots of information. It defines all the keywords and explains what form they take and what their effect is. You won't yet be able to understand everything that the helper utility tells you but it can still be a very useful resource. \n",
      "\n",
      "Another way to get the same information, is to type the function name (**hist** in this case) follow by the opening parenthesis **(** and then simply pause a moment, try it in the cell below:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This will create a floating pop up with the same information, you can press the plus icon in the top right of the popup to expand. If you want to reopen the pop up you can simply delete the first opening parenthesis and put it back. Try it on the line above."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading pylab gives us access to basic statistical functions like the mean:\n",
      "\n",
      "    mean(d)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The median:\n",
      "   \n",
      "   \n",
      "    median(d)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The standard deviation:\n",
      "    \n",
      "    std(d)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The percentile:\n",
      "    \n",
      "    first_q = percentile(d,25)\n",
      "    third_q = percentile(d,75)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That can be used to compute the interquartile range:\n",
      "    \n",
      "    third_q - first_q"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The standard error of the mean is a very important quantity which we will cover in further depth during the exercises. It expresses how uncertain we are in the mean value we have computed. \n",
      "\n",
      "We can calculate the standard error from the standard deviation and the square root of the number of elements.\n",
      "\n",
      "To compute the number of elements we need another built-in function **len**\n",
      "\n",
      "    no_elements = len(d)\n",
      "    std(d)/no_elements**0.5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also perform these statistical measures on 2d arrays (I.E. matrices), we'll make a 2d array using a function **randn**. This generates arrays of random numbers, to make a 5x5 array of random numbers we would use\n",
      "\n",
      "    m=randn(5,5)\n",
      "    m"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we take the mean directly we get the mean of all the numbers in the matrix, in much the same way that we would for a 1d array:\n",
      "    \n",
      "    mean(m)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However with a matrix we have the possibility to compute the means of all the columns, or all the rows individually. We do this with the axis keyword. To compute the means of the columns we would use:\n",
      "    \n",
      "    mean(m, axis=0)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This gives us an array where the first element is the mean of the first column of the 2d array, the second element is the mean of the second column of the 2d array etc."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Likewise to compute the means of the rows we would use:\n",
      "    \n",
      "    mean(m, axis=1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The same is true of the other statistical functions.\n",
      "\n",
      "    percentile(m, 25, axis=1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Filtering data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to the many ways to access the elements of an array that we covered yesterday there is a final method that is very useful. Here we access a subset of the data not by specifying the *indices* we want to include but instead by specifying their *values*. Thus we can select all elements of an array that are greater than a certain value. This is very useful to filter data in order to remove spurious values and outliers. Recalling that d is the dataset we loaded above. To select all values larger than 3 we use:\n",
      "    \n",
      "    d[d>3]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This can be combined with the statistical functions, thus to select data above the mean we would use:\n",
      "    \n",
      "    large_d = d[d>mean(d)]\n",
      "    hist(large_d)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can chain the filtering process. Thus to select the data inside the interquartile range we first select the data that is above the 25th percentile:\n",
      "    \n",
      "    q1 = percentile(d,25)\n",
      "    last_75_d = d[d>q1]\n",
      "    hist(last_75_d)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And then of that we select the data that is below the 75th percentile:\n",
      "    \n",
      "    q3 = percentile(d,75)\n",
      "    mid_d = last_75_d[last_75_d<q3]\n",
      "    hist(mid_d)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fitting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When we plot functions we do so by generating data corresponding to the function e.g. $f(x) = 3x+5$\n",
      "    \n",
      "    X = linspace(0,20)\n",
      "    f_X = 3*X+5\n",
      "    plot(X,f_X)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = linspace(0,20)\n",
      "f_X = 3*X+5\n",
      "plot(X,f_X)\n",
      "show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEACAYAAACuzv3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7ffbf10b26d0>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case we started with a known function and generated some data using it. \n",
      "\n",
      "We often wish to do the reverse, that is start with some set of data and try and find the best function that describes it this process is called fitting. In the rest of this workshop we will focus on fitting data to straight line functions $f(x) = mx + c$. This is called *linear fitting*.\n",
      "\n",
      "To illustrate this process we will define some linear data and use **nrand** to add some random noise to simulate some experimental data:\n",
      "\n",
      "    X = linspace(0,20,20)\n",
      "    Y = 3*X+5\n",
      "    noisey_Y = Y + 10 * randn(100)/2\n",
      "    plot(X,Y)\n",
      "    plot(X, noisey_Y, linestyle='', marker='^')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we will try and fit the data to a straight line i.e. find the possible values for the gradient and intercept. We'll use the **polyfit** function to do this:\n",
      "\n",
      "    polyfit(X, noisey_Y,1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Polyfit allows us to fit not just to straight lines but also to polynomials of arbitrary degree as we're focusing on straight lines we include a 1 as the third argument. This means we will fit to a polynomial of degree one. I.E. a straight line.\n",
      "\n",
      "The outputs are the coefficents that define the fit. For a straight line that means the gradient and the intercept of the line.\n",
      "\n",
      "We often want some more detail about the fitting process, in particular we'd like an estimate of how accurate our extracted parameters are. We can get this extra information by passing in an additional keyword:\n",
      "\n",
      "    polyfit(X, noisey_Y, 1, cov=True)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By adding in *cov=True* we get back an additional matrix of four numbers, these express our uncertainty in the extracted coefficients. To be more explicit the diagonal elements of this matrix give us the variance $\\sigma{}^2$ of our estimates for the coefficients - The upper left diagonal element is the variance for the gradient and the lower right diagonal element is the variance for the intercept.\n",
      "\n",
      "In order to turn these into the standard error for the coefficient we need to take the square roots of these values. We'll use the **print** function to display several of the relevant values together:\n",
      "\n",
      "    poly_out = polyfit(X, noisey_Y,1, cov=True)\n",
      "    params = poly_out[0]\n",
      "    poly_cov = poly_out[1]\n",
      "    m=params[0]\n",
      "    c=params[1]\n",
      "\n",
      "    stand_e_m = poly_cov[0][0] ** 0.5\n",
      "    stand_e_c = poly_cov[1][1] ** 0.5\n",
      "\n",
      "    print('Gradient = ',m)\n",
      "    print('Intercept = ',c)\n",
      "    print('Standard Error of the gradient = ', stand_e_m)\n",
      "    print('Standard Error of the intercept = ',stand_e_c)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looking at my numbers I have an uncertainty in the gradient of about 7.5% and an uncertainty in the intercept of about 30%, because we're generating the noise on the fly your numbers will be slightly different to mine but your figures should be somewhere in the same ballpark. \n",
      "\n",
      "These values are important for us to know but if our data is not well described by the model we've chosen (in this case a straight line) then they don't mean very much - expressing our certainty in an estimate for the single fixed gradient that characterises the process beneath the noise doesn't make a lot of sense if the prcoess beneath the noise is not characterised by a single fixed gradient."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll create a new set of data using our newly defined model and plot them alongside the original data, we'll also plot the the original function that we used to create our data in the first place:\n",
      "\n",
      "    fitted_Y = m*X + c\n",
      "    plot(X,Y)\n",
      "    plot(X, noisey_Y, linestyle='', marker='^')\n",
      "    plot(X, fitted_Y, linestyle='--')\n",
      "    show()\n",
      "\n",
      "    print('Gradient = ',m)\n",
      "    print('Intercept = ',c)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Even though our data had quite a lot of noise in it the fact that we had a lot of data points means our fit is pretty good though it does not perfectly regenerate the function we used to generate the data that lies beneath the noise."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to using the covariance matrix to gauge the accuracy of our parameters we can get an idea of whether our model choice is reasonable by computing and examining the *residuals*. These are the differences between the predictions we are making using our model and the actual measured data.\n",
      "\n",
      "    residuals = fitted_Y - noisey_Y"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll plot the residuals directly and a line along y=0 for comparison:\n",
      "\n",
      "    plot(X, residuals, marker='^', linestyle='')\n",
      "    plot(X,X-X,linestyle='--')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that the risiduals are clustered close to 0 and we see no obvious trend in their distribution. A clear trend in the residuals is an indicator that our model choice (in this case a straight line) is not capturing all the structure of our data and hence could be improved. Let's see what happens if we pick a different dataset that we know is not well described using a straight line.\n",
      "\n",
      "    Y2 = 0.5*X**2 -5*X + 50\n",
      "    noisey_Y2 = Y2 + 10 * randn(20)/3\n",
      "    plot(X,Y2)\n",
      "    plot(X, noisey_Y2, linestyle='', marker='^')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's try and fit a straight line as before:\n",
      "\n",
      "    poly_out = polyfit(X, noisey_Y2, 1, cov=True)\n",
      "    params = poly_out[0]\n",
      "    poly_cov = poly_out[1]\n",
      "    m=params[0]\n",
      "    c=params[1]\n",
      "\n",
      "    fitted_Y2 = m*X + c\n",
      "\n",
      "    plot(X,Y2)\n",
      "    plot(X, noisey_Y2, linestyle='', marker='^')\n",
      "    plot(X, fitted_Y2, linestyle='--')\n",
      "    show()\n",
      "\n",
      "    print('Gradient = ',m)\n",
      "    print('Intercept = ',c)\n",
      "    print('Standard Error of the gradient = ', poly_cov[0][0]**0.5)\n",
      "    print('Standard Error of the intercept = ', poly_cov[1][1]**0.5)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that despite the above data not being linear, the standard error for the gradient is not that much bigger than for the linear data set we used above. (If our linear data had been less noisy we would see a bigger difference in the standard error between these two cases). Let's now plot the residuals and see what they show:\n",
      "    \n",
      "    residuals_2 = fitted_Y2 - noisey_Y2\n",
      "    plot(X, residuals_2, marker='^', linestyle='None')\n",
      "    plot(X,X-X,linestyle='--')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This time we see a definite pattern indicating our model choice could be improved."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Partial Fits"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose we have some measurements that we think should lie on a straight line, e.g. we're measuring the UV/VIS absorbance of species at different concentrations. We want to extract the gradient frmom this line. The problem is that our experimental setup means we only get the straight line behaviour for a subset of the data.\n",
      "\n",
      "Let's look at the following data:\n",
      "\n",
      "    x= arange(1.0,100,4)\n",
      "    y = array([ 0.03231454,  0.13898134,  0.2713996 ,  0.3306628 ,  0.43943964,  0.55986173,  0.65984714,  0.78631773,\n",
      "            0.89412865,  0.98014824,  1.06925855,  1.14170126,  1.20720018,  1.31978907,  1.28525302,  1.34782115,\n",
      "            1.31360386,  1.43122401,  1.40408662,  1.38122363,  1.39562417,  1.34654361,  1.42412321,  1.3962572 ,\n",
      "            1.31714601])\n",
      "    plot(x,y, marker='^', linestyle='')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that the straight line portion of the curve is at the beginning and ends somewhere around x=40/y=1.1 i.e. the 11th data point.\n",
      "\n",
      "First we'll try applying our linear fit to the entire set of data:\n",
      "\n",
      "    bad_fit_params = polyfit(x, y, 1)\n",
      "    bad_m = bad_fit_params[0]\n",
      "    bad_c = bad_fit_params[1]\n",
      "      \n",
      "    print('Gradient = ',bad_m)\n",
      "    print('Intercept = ',bad_c)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 163
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll try restricting our fit to the linear portion of the data, we first select the data we are interested in using the index then we we apply our fit to the restricted dataset.\n",
      "    \n",
      "    fitting_xdata = x[:11]\n",
      "    fitting_ydata = y[:11]\n",
      "\n",
      "    good_fit_params = polyfit(fitting_xdata, fitting_ydata, 1)\n",
      "    good_m = good_fit_params[0]\n",
      "    good_c = good_fit_params[1]\n",
      "\n",
      "    print('Gradient = ',good_m)\n",
      "    print('Intercept = ',good_c)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 164
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see the values we get for the gradient and intercept are quite different. If we visualize both fits we'll see why. First we'll create the fitted data we're going to plot:\n",
      "\n",
      "    bad_fitted_y = bad_m*x + bad_c\n",
      "    good_fitted_y = good_m*x + good_c"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll plot it along with the original data:\n",
      "\n",
      "    plot(x,y, linestyle='', marker='^')\n",
      "    plot(x, bad_fitted_y, linestyle='--', color='red', label='full_fit')\n",
      "    plot(x, good_fitted_y, linestyle='--', color='blue', label='partial_fit')\n",
      "    legend(loc='center right')\n",
      "    \n",
      "    ylim([0,1.6])\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that partial fit matches the linear portion of the data that we are interest in whilst the full fit is skewed by the presence of the excess non linear data."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Weighted Fits"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus far our fitting process has assumed all the data points are equally significant in many cases however we know that some of the measurements we have made are much more uncertain than others, we'd like to provide the fitting algorithm with this information so that when it tries to find the best gradient and intercept it cares more about the points that have greater certainty than those measurements we have less confidence in.\n",
      "\n",
      "Let's imagine have some measurements of the pressure of a Nobel gas in a fixed container as the temperature is increased. Lets llook at the data:\n",
      "\n",
      "    gas_data = loadtxt('ideal_gas_data.txt')\n",
      "    temp = gas_data[:,0]\n",
      "    pressure = gas_data[:,1]\n",
      "\n",
      "    plot(temp, pressure, marker='^', linestyle='')\n",
      "    xlabel('Temperature /K')\n",
      "    ylabel('Pressure /Pa')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 167
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We believe that the nobel gas obeys the equation $pV=nRT$ where p is pressure, V volume, n the number of moles of gas, R the ideal gas constant and T the temperature. \n",
      "\n",
      "Hence that if we plot pressure against temperature for a fixed number moles of gas in a fixed volume we should have a straight line with gradient $nR/V$. We will use the fact that we know we have 1 mole of gas and that the volume of the box is $2.4*10^{-2} m^3$ to determine an estimate for the gas constant. \n",
      "\n",
      "We also know that that the instrument we are using to measure the pressure becomes less and less accurate the hotter it gets. Infact let us suppose that our instrument is calibrated to perform perfect measurements at zero degrees C but that error associated with measurements grows as the square of the temperature above 0 degrees C. We'll use the **errorbar** function to visualise our data together with the uncertainty.\n",
      "\n",
      "    std_e = (temp-273)**2\n",
      "\n",
      "    errorbar(temp, noisey_p, marker='^', linestyle='', yerr=std_e) \n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 167
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have set the scene let's try fitting a straight line to our data and extracting an estimate for the ideal gas constant. Treating all the points equally we get the following:\n",
      "    \n",
      "    poly_out = polyfit(temp, noisey_p, 1, cov=True)\n",
      "    params = poly_out[0]\n",
      "    poly_cov = poly_out[1]\n",
      "    m = params[0]\n",
      "    c = params[1]\n",
      "\n",
      "    plot(temp, m*temp+c, linestyle='--')\n",
      "    errorbar(temp, noisey_p, marker='^', linestyle='', yerr=std_e) \n",
      "    show()\n",
      "\n",
      "    print('Gradient = ',m)\n",
      "    print('Intercept = ',c)\n",
      "    print('Standard Error of the gradient = ', poly_cov[0][0]**0.5)\n",
      "    print('Standard Error of the intercept = ', poly_cov[1][1]**0.5)\n",
      "    print('Estimate for R =',2.4e-2*m)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 168
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our error for the gradient is significant and our estimate for R is poor. Now we'll fit and provide weights to tell polyfit how significant the points are. The standard way of weighting is to weight a point by $\\frac{1}{\\sigma{}^2}$. where $\\sigma$ is the standard error. This will mean the points with the largest uncertainty have the smallest weights which is what we want.\n",
      "\n",
      "    poly_out = polyfit(temp, noisey_p, 1, cov=True, w=1/std_e**2)\n",
      "    params = poly_out[0]\n",
      "    poly_cov = poly_out[1]\n",
      "    m = params[0]\n",
      "    c = params[1]\n",
      "\n",
      "    plot(temp, m*temp+c, linestyle='--')\n",
      "    errorbar(temp, noisey_p, marker='^', linestyle='', yerr=std_e) \n",
      "    show()\n",
      "\n",
      "    print('Gradient = ',m)\n",
      "    print('Intercept = ',c)\n",
      "    print('Standard Error of the gradient = ', poly_cov[0][0]**0.5)\n",
      "    print('Standard Error of the intercept = ', poly_cov[1][1]**0.5)\n",
      "    print('Estimate for R =',2.4e-2*m)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 168
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that the error in the gradient has decreased significantly and our estimate for R is now much closer to the true ideal gas constant."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Exercises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calculate and plot the residuals *for the first 11 data points* in the above data set for both the full fit and the partial fits. Can you send a trend in the residuals for the two fits?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}