{
 "metadata": {
  "kernelspec": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "name": "",
  "signature": "sha256:9a071e39a856c1f0bfa2e4cc0412c477581d95edebe4d1d848c38b7d3fb5e4a7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# An Introduction to Plotting and Data Analysis in Python: Workshop 2\n",
      "[Clyde Fare](mailto://c.fare12@imperial.ac.uk) and [Jo\u00e3o Pedro Malhado](mailto://malhado@imperial.ac.uk), Imperial College London. \n",
      "\n",
      "The notebook is licensed under a [Creative Commons Attribution 3.0 (CC-by) license](http://creativecommons.org/licenses/by/3.0/us)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Overview\n",
      "--------\n",
      "During this workshop we will recap what we covered in workshop 1 then build on it covering importing of modules to extend the functionality we have access to and reading and writing of data and plots. We will then learn to fit data and use basic statistics to characterise how good our fit is.\n",
      "\n",
      "This is an interactive tutorial - as you go through it any time you see something that looks like this:\n",
      "\n",
      "    a = \"Hello\"\n",
      "   \n",
      "that's followed by an empty *code cell* (a light grey rectangle with a label like *\"In[ ]\"*), you should \n",
      "type the expression in the code cell, hit Shift+Return to *execute* it, and note the output.\n",
      "\n",
      "Limit copying and pasting to cells requiring more than 5 lines! You'll learn the concepts better if you type them out yourself.\n",
      "\n",
      "Warning periodically save your work by pressing the save icon above (We'll cover the other icons later but if you want to know what they are now hover your cursor over them)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Recap from workshop 1"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Notebook"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are working inside an interactive Python Notebook. It is composed of code cells where Python code can be executed and non code cells, where descriptive material can be placed.\n",
      "\n",
      "The icons at the top of the page allow us to save the page, add new cells, cut, copy and paste cells, move cells up or down, execute the highlighted cell, halt and reset the current python kernel.\n",
      "\n",
      "We can convert a highlighted cell to a different type of cell using the dropdown menu to the immediate right of the icons.\n",
      "\n",
      "We can execute a code cell/render a markdown cell with Shift+Return.\n",
      "\n",
      "If we want to have direct access to the plotting and numerical functions and include our plots directly in the notebook we need to execute\n",
      "\n",
      "    %pylab inline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To help us visualize some of the data we will add another command that sets how many lines is to display variables\n",
      "\n",
      "    set_printoptions(linewidth=120)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Variables"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Variables, allow us to refer to data objects with names:\n",
      "    \n",
      "    x=3\n",
      "    y=array([1,2,3])\n",
      "    z=x*y\n",
      "    z"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Arrays"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Arrays are collections of numbers, that we can operate on collectively and are the containers for our data. There are special commands **linspace** and **arange** for creating arrays.\n",
      "\n",
      "**linspace** creates arrays of equally spaced numbers where we specify the initial value, the final value and how many numbers we want inbetween\n",
      "\n",
      "    linspace(-pi, pi, 10)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**arange** creates arrays of equally spaced numbers where we specify the initial value, a stop value (that will not be included), and the interval size:\n",
      "    \n",
      "    arange(0, 10, 3)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And we can refer to elements of the data in an array by using square brackets and the index of the element we want. Remembering the the first element corresponds to index zero.\n",
      "\n",
      "    arange(0,10,1)[0]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    arange(0,10,1)[5]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also refer to slices of the data using a syntax similar to arange where a colon is used in place of the comma.\n",
      "\n",
      "    my_array = arange(0,10,1)\n",
      "    my_array[0:10:3]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus the above slice takes the zeroth (first) element of my_array and then every 3rd element up to but not including 10.\n",
      "\n",
      "If the first index is omitted, it will start at the zeroth index.\n",
      "If the second index is omitted we move up to but not including the N+1th element\n",
      "If the third index is omitted the step size is 1 i.e we include all elements between the first index and the second index - 1\n",
      "\n",
      "Thus\n",
      "    \n",
      "    my_array[::]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Arrays can be multidimensional\n",
      "\n",
      "    my_2d_array = array([[0, 3, 6, 9], [1, 4, 7, 10], [2, 5, 8, 11], [3, 6, 9, 12]])\n",
      "    my_2d_array"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Where indices now refer to the indidual rows:\n",
      "    \n",
      "    my_2d_array[1]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can apply the same indexing mechanism as we did for 1d array except we use a comma to seperate the indexing that refers to the rows and the indexing that refers to the columns:\n",
      "    \n",
      "    my_2d_array[1:4:2,0:3:2]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which is summarised by the following diagram:\n",
      "\n",
      "<img src=\"files/numpy_indexing.png\" />"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can perform mathematical operations on arrays, which performs the operation on all elements of the array\n",
      "\n",
      "    sin(my_array)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Plots"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can plot using the **plot** command and display using the **show** command\n",
      "\n",
      "    plot(arange(10), arange(10)**2, label='$x^2$')\n",
      "    plot(arange(10), arange(10)**3, label='$x^3$',marker='o',linestyle='None')\n",
      "    title('My reminder plot')\n",
      "    xlabel('x')\n",
      "    ylabel('y')\n",
      "    legend()\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are many options\n",
      "\n",
      "    age= arange(10)\n",
      "    p_human = age**2\n",
      "    p_badger = age**3\n",
      "\n",
      "    plot(age, p_human, linewidth=2.5, linestyle=\"--\", label='Humans')\n",
      "    plot(age, p_badger, marker='^', color='red', label='Badgers',marker='^',linestyle='None' )\n",
      "    title('My reminder plot')\n",
      "    xlabel('Age')\n",
      "    ylabel('Power')\n",
      "    legend()\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Going further"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Log plot"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are many occasions where we want to plot data on a logarthimic scale. To illustrate this, in the next code cell we define the variable *r_data* with some radioactivity data. Namely the half lives for some radioactive elements and their atomic numbers. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r_data=array([[  43,   1.29928320e+14],\n",
      "       [  61,   5.59133280e+08],\n",
      "       [  83,   5.99184000e+26],\n",
      "       [  84,   3.21982560e+09],\n",
      "       [  85,   2.90160000e+04],\n",
      "       [  86,   3.30349968e+05],\n",
      "       [  87,   1.30200000e+03],\n",
      "       [  88,   5.01422400e+10],\n",
      "       [  89,   6.87059064e+08],\n",
      "       [  90,   4.43396160e+17],\n",
      "       [  91,   1.03400237e+12],\n",
      "       [  92,   1.40997456e+17],\n",
      "       [  93,   6.76604880e+13],\n",
      "       [  94,   2.50080480e+15],\n",
      "       [  95,   2.32987968e+11],\n",
      "       [  96,   4.91961600e+14],\n",
      "       [  97,   4.34881440e+10],\n",
      "       [  98,   2.84013216e+10],\n",
      "       [  99,   4.07508192e+07],\n",
      "       [  100,   8.68320000e+06],\n",
      "       [  101,   4.44960000e+06],\n",
      "       [  102,   1.00080000e+04],\n",
      "       [  103,   3.60000000e+04],\n",
      "       [  104,   4.71600000e+04],\n",
      "       [  105,   2.00160000e+04],\n",
      "       [  106,   6.98400000e+03],\n",
      "       [  107,   5.40000000e+03],\n",
      "       [  108,   3.99600000e+03],\n",
      "       [  109,   1.80000000e+03],\n",
      "       [  110,   2.40000000e+02],\n",
      "       [  111,   6.00000000e+02],\n",
      "       [  112,   2.40000000e+03],\n",
      "       [  113,   1.20000000e+03],\n",
      "       [  114,   7.98000000e+01],\n",
      "       [  115,   6.00000000e+01],\n",
      "       [  116,   1.20000000e-01],\n",
      "       [  117,   5.00000000e-02],\n",
      "       [  118,   5.00000000e-03]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we simply plot atomic number versus half life. What we see is not very informative:\n",
      "\n",
      "    atomic_nos = r_data[:,0]\n",
      "    half_lives = r_data[:,1]\n",
      "    plot(atomic_nos, half_lives)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we take a look at the half lives we can see why:\n",
      "    \n",
      "    half_lives"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that they range from $10^{-3}$ for Ununoctium to $10^{26}$ seconds for Bismuth - 29 orders of magnitude! Because of this guargantuan range of values plotting the raw data reveals almost nothing. The plot is dominated by the half life of Bismuth and none of the other variation is visible.\n",
      "\n",
      "If we scale the y-axis so that it is logarithmic i,e the units are orders of magnitude then we should have a much better way to visualize the data. We can use the **xscale** and **yscale** functions to do this.\n",
      "\n",
      "    figure(figsize=[12,8])\n",
      "    yscale('log')\n",
      "    plot(atomic_nos, half_lives, marker='o')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which allows us a much better visualization of the data.\n",
      "\n",
      "The above is equivalent to\n",
      "\n",
      "    figure(figsize=[12,8])\n",
      "    plot(atomic_nos, log(half_lives), marker='o')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A plot using logarithmic scaling for one axis and normal linear scaling for another is known as a semi-log plot. It is also possible to create a log-log plot by scaling both axis. This can be useful to pull out linear relationships in otherwise non-linear data. We will see an example of this in workshop 3."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Reading and writing data to files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The most common use case you will have when plotting data is plotting data that has been generated else where.  Most modern measuring instruments will be coupled to a computer or otherwise will be able to store your data in a file. **You should always aim to store your measurement data in a text file**. That means you need a way to load data into a notebook.\n",
      "\n",
      "There are severeal ways of doing this, the simplest is **loadtxt**\n",
      "\n",
      "This loads data from text files, provided the data layed out in a regular format. If you take a look at the file [data.txt](./data.txt) which is in the same directory as this notebook. You will see each lines contains numbers separated by spaces.\n",
      "\n",
      "loadtxt will load this data into an array for us via:\n",
      "\n",
      "    our_data = loadtxt(\"data.txt\")"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    our_data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We could load a text file seperated by commas like [data2.txt](./data2.csv) via:\n",
      "    \n",
      "    loadtxt(\"data2.txt\", delimiter=',')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will now modify the data we just loaded by shifting the values of the second column by -2 and save it back to a file.\n",
      "\n",
      "    modified_data = our_data - array([0,2,0,0])"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to save the modified data array we can use the command **savetxt**, which works analagously to loadtxt thus\n",
      "    \n",
      "    savetxt('my_data_file.txt', modified_data)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Creates the file my_data_file.txt, with the data values separated by spaces.\n",
      "\n",
      "If we wanted data separated by commas we would use:\n",
      "    \n",
      "    savetxt('my_data_file2.txt', modified_data, delimiter=',')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take a look at the two files you've just produced: [my_data_file.txt](./my_data_file.txt) and [my_data_file2.txt](./my_data_file2.txt)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Basic statistics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets load up a data set and plot a histogram of the data\n",
      "\n",
      "    d=loadtxt('d1.txt')\n",
      "    hist(d)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Histograms tell us how many data points there are in a particular range of the data. By default the *hist* command creates 10 bins, equally spaced between the lowest value in the data set and the highest value in the dataset."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use the functions **min** and **max** to find the largest and smallest values in an array.\n",
      "\n",
      "    min(d)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    max(d)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Armed with these values we can check our histogram makes sense. We said before there were 10 bins by default, now that we know the maximum and minimum values we can see that the bin size must be:\n",
      "    \n",
      "    ( max(d) - min(d) )/10"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(Note we had to use brackets because we want the subtraction to occur before the division.)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The width of each bin is about 0.75 and we start at about -3.66 and end at about 3.8. Look at the above histogram and make sure that this makes sense - where do you expect the third bin from left to start?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can change the number of bins using the the bin keyword:\n",
      "    \n",
      "    hist(d, bins=20)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are many options to customise histograms, we won't go through them all. But this is a good point to demonstrate a way to use the built in help system. We can automatically get more information on a particular function by typing the function followed by a question mark:\n",
      "    \n",
      "    hist?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This pops up a footer window that has lots of information. It defines all the keywords and explains what form they take and what their effect is. You won't yet be able to understand everything that the helper utility tells you but it can still be a very useful resource. \n",
      "\n",
      "Another way to get the same information, is to type the function name (**hist** in this case) follow by the opening parenthesis **(** and then simply pause a moment, try it in the cell below:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This will create a floating pop up with the same information, you can press the plus icon in the top right of the popup to expand. If you want to reopen the pop up you can simply delete the first opening parenthesis and put it back. Try it on the line above."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading pylab gives us access to basic statistical functions like the sample mean, defined as\n",
      "\n",
      "$$\\bar{x}=\\frac{\\sum_i^N x_i}{N} ,$$\n",
      "\n",
      "where $x_i$ is the value of each element and $N$ is the total number of data points.\n",
      "\n",
      "    mean(d)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The median:\n",
      "   \n",
      "   \n",
      "    median(d)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The sample standard deviation defined as\n",
      "\n",
      "$$s_x=\\sqrt{\\frac{\\sum_i^N(x_i-\\bar{x})^2}{N-1}}$$\n",
      "    \n",
      "    std(d,ddof=1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note the *ddof=1* parameter set above which relates to the $N-1$ term in the denominator in the definition of standard deviation. Different values of *ddof* have different statistical meaning. We will be dealing exclusivelly with *ddof=1*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The percentile:\n",
      "    \n",
      "    first_q = percentile(d,25)\n",
      "    third_q = percentile(d,75)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That can be used to compute the interquartile range:\n",
      "    \n",
      "    third_q - first_q"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The standard error of the mean $\\sigma_{\\bar{x}}$ is an important quantity which we will see again in the exercises. It expresses how uncertain we are in the mean value we have computed. When reporting an estimate resulting from several measurements, we should use $\\bar{x} \\pm \\sigma_{\\bar{x}} units$.\n",
      "\n",
      "We can calculate the standard error from the standard deviation and the square root of the number of elements:\n",
      "\n",
      "$$\\sigma_{\\bar{x}}=\\frac{s_x}{\\sqrt{N}}=\\sqrt{\\frac{\\sum_i^N (x_i-\\bar{x})^2}{N(N-1)}}$$\n",
      "\n",
      "To compute the number of elements we need another built-in function **len**\n",
      "\n",
      "    no_elements = len(d)\n",
      "    std(d,ddof=1)/no_elements**0.5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also perform these statistical measures on 2d arrays (i.e. matrices), we'll make a 2d array using a function **randn**. This generates arrays of random numbers, to make a 5x5 array of random numbers we would use\n",
      "\n",
      "    m=randn(5,5)\n",
      "    m"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we take the mean directly we get the mean of all the numbers in the matrix, in much the same way that we would for a 1d array:\n",
      "    \n",
      "    mean(m)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However with a matrix we have the possibility to compute the means of all the columns, or all the rows individually. We do this with the axis keyword. To compute the mean of each column we would use:\n",
      "    \n",
      "    mean(m, axis=0)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This gives us an array where the first element is the mean of the first column of the 2d array, the second element is the mean of the second column of the 2d array etc."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Likewise to compute the mean of each row we would use:\n",
      "    \n",
      "    mean(m, axis=1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The same is true of the other statistical functions.\n",
      "\n",
      "    percentile(m, 25, axis=1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Filtering data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to the many ways to access the elements of an array that we covered yesterday there is a final method that is very useful. Here we access a subset of the data not by specifying the *indices* we want to include but instead by specifying their *values*. Thus we can select all elements of an array that are greater than a certain value. This is very useful to filter data in order to remove spurious values and outliers. Recalling that d is the dataset we loaded above. To select all values larger than 3 we use:\n",
      "    \n",
      "    d[d>3]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This can be combined with the statistical functions, thus to select data above the mean we would use:\n",
      "    \n",
      "    large_d = d[d>mean(d)]\n",
      "    hist(large_d)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can chain the filtering process. Thus to select the data inside the interquartile range we first select the data that is above the 25th percentile:\n",
      "    \n",
      "    q1 = percentile(d,25)\n",
      "    last_75_d = d[d>q1]\n",
      "    hist(last_75_d)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And then of that we select the data that is below the 75th percentile:\n",
      "    \n",
      "    q3 = percentile(d,75)\n",
      "    mid_d = last_75_d[last_75_d<q3]\n",
      "    hist(mid_d)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus far we have been filtering a 1 dimensional array but the filering process works just as well if we have a two diemnsional array, when we discussed the *loadtxt* function above we loaded some data to a variable named 'our_data':\n",
      "\n",
      "    our_data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will now filer this data, taking only the lines where the values in the second column are greater than 5:\n",
      "    \n",
      "    column_2 = our_data[:,1]\n",
      "    our_data[column_2>5]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fitting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When we plot functions we do so by generating data corresponding to the function e.g. $f(x) = 3x+5$\n",
      "    \n",
      "    X = linspace(0,20)\n",
      "    f_X = 3*X+5\n",
      "    plot(X,f_X)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case we started with a known function and generated some data using it. \n",
      "\n",
      "We often wish to do the reverse, that is start with some set of data and try and find the best function that describes it this process is called fitting. In the rest of this workshop we will focus on fitting data to straight line functions $f(x) = mx + c$. This is called *linear fitting*.\n",
      "\n",
      "To illustrate this process we will define some linear data and use **nrand** to add some random noise to simulate some experimental data:\n",
      "\n",
      "    X = linspace(0,20,20)\n",
      "    Y = 3*X+5\n",
      "    noisey_Y = Y + 10 * randn(20)/2\n",
      "    plot(X,Y)\n",
      "    plot(X, noisey_Y, linestyle='', marker='^')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we will try and fit the data to a straight line i.e. find the possible values for the gradient and intercept. We'll use the **polyfit** function to do this:\n",
      "\n",
      "    polyfit(X, noisey_Y,1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Polyfit allows us to fit not just to straight lines but also to polynomials of arbitrary degree. As we're focusing on straight lines we include a 1 as the third argument. This means we will fit to a polynomial of degree one, i.e. a straight line.\n",
      "\n",
      "The outputs are the coefficents that define the fit. For a straight line that means the gradient and the intercept of the line.\n",
      "\n",
      "We often want some more detail about the fitting process, in particular we would like an estimate of how precise our extracted parameters are. We can get this extra information by passing in an additional keyword:\n",
      "\n",
      "    polyfit(X, noisey_Y, 1, cov=True)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By adding in *cov=True* we get back an additional array (more specifically a matrix) of four numbers. These express our uncertainty in the extracted coefficients. To be more explicit the diagonal elements of this matrix give us the variance $\\sigma{}^2$ of our estimates for the coefficients: The upper left diagonal element (index [0,0]) is the variance for the gradient and the lower right diagonal element (index [1,1]) is the variance for the intercept.\n",
      "\n",
      "In order to turn these into the standard error for the coefficient we need to take the square roots of these values. In the lines bellow we assign the fitting parameters to convenient variable names:\n",
      "\n",
      "    fit = polyfit(X, noisey_Y,1, cov=True)\n",
      "    params = fit[0]\n",
      "    params_cov = fit[1]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets look at our fit prameters\n",
      "\n",
      "    params"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "where the first element is the slope and the second is the intercept.\n",
      "\n",
      "Looking now at the uncertainties\n",
      "\n",
      "    params_cov ** 0.5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looking at my numbers I have an uncertainty in the gradient of about 7.5% and an uncertainty in the intercept of about 30%. Because we are generating the noise on the fly your numbers will be slightly different to mine but your figures should be somewhere in the same ballpark.\n",
      "\n",
      "These values are important for us to know but if our data is not well described by the model we've chosen (in this case a straight line) then they don't mean very much - expressing our certainty in an estimate for the single fixed gradient that characterises the process beneath the noise doesn't make a lot of sense if the process beneath the noise is not characterised by a single fixed gradient."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll create a new set of data using our newly defined model and plot them alongside the original data, we'll also plot the the original function that we used to create our data before we added noise to it:\n",
      "\n",
      "    m=params[0]\n",
      "    c=params[1]\n",
      "    \n",
      "    fitted_Y = m*X + c\n",
      "    plot(X,Y)\n",
      "    plot(X, noisey_Y, linestyle='', marker='^')\n",
      "    plot(X, fitted_Y, linestyle='--')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Even though our data had quite a lot of noise in it the fact that we had a lot of data points means our fit is pretty good though it does not perfectly regenerate the function we used to generate the data that lies beneath the noise, the parameters estimate should be correct plus or minus the obtained uncertainty. (If by chance they don't, you didn't necessarily do something wrong, you are an outlier, and you can ask the demonstrator [why this might have happened](http://commons.wikimedia.org/wiki/File:Standard_deviation_diagram.svg).)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to using the covariance matrix to gauge the accuracy of our parameters we can get an idea of whether our model choice is reasonable by computing and examining the *residuals*. These are the differences between the predictions we are making using our model and the actual measured data.\n",
      "\n",
      "    residuals = fitted_Y - noisey_Y"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll plot the residuals directly and a line along y=0 for comparison:\n",
      "\n",
      "    plot(X, residuals, marker='^', linestyle='')\n",
      "    plot(array([X[0],X[-1]),array([0,0]),linestyle='--')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that the residuals are clustered close to 0 and we see no obvious trend in their distribution. A clear trend in the residuals is an indicator that our model choice (in this case a straight line) is not capturing all the structure of our data and hence could be improved. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "One should not fit blindly"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose we have some measurements and we know the relationship between the variables should be linear (i.e. they should lie on a straight line)\n",
      "\n",
      "Let's look at the following data:\n",
      "\n",
      "    x= arange(1.0,100,4)\n",
      "    y = array([ 0.03231454,  0.13898134,  0.2713996 ,  0.3306628 ,  0.43943964,  0.55986173,  0.65984714,  0.78631773,\n",
      "            0.89412865,  0.98014824,  1.06925855,  1.14170126,  1.20720018,  1.31978907,  1.28525302,  1.34782115,\n",
      "            1.31360386,  1.43122401,  1.40408662,  1.38122363,  1.39562417,  1.34654361,  1.42412321,  1.3962572 ,\n",
      "            1.31714601])\n",
      "    plot(x,y, marker='^', linestyle='')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that the data is not a straight line throughout. The straight line portion of the curve we are interested in is at the beginning, ending somewhere around x=40/y=1.1 i.e. the 11th data point.\n",
      "\n",
      "First we'll try applying our linear fit to the entire set of data:\n",
      "\n",
      "    bad_fit = polyfit(x, y, 1, cov=True)\n",
      "    bad_params = bad_fit[0]\n",
      "    bad_params_cov = bad_fit[1]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's plot the data with the bad fit to data:\n",
      "\n",
      "    bad_m = bad_params[0]\n",
      "    bad_c = bad_params[1]\n",
      "    \n",
      "    bad_fitted_y = bad_m*x + bad_c\n",
      "    \n",
      "    plot(x,y, linestyle='', marker='^')\n",
      "    plot(x, bad_fitted_y, linestyle='--', color='red')\n",
      "    show()\n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And the residuals\n",
      "\n",
      "    bad_res = y - bad_fitted_y\n",
      "    \n",
      "    plot(x, bad_res, marker='^', linestyle='', color='red')\n",
      "    plot(array([x[0],x[-1]]),array([0,0]),linestyle='--')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We note that the residuals don't have a random distribution around zero, they present a curved pattern. A clear pattern in the residuals indicates the fit is not ideal. Note that the value of the uncertainties of the parameters do not provide an indication of whether your model/fit function is not a good description of your data points. \n",
      "\n",
      "Plotting the residuals will give you a hint."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll try restricting our fit to the linear portion of the data. We first select the data we are interested in using the index then we apply our fit to the restricted dataset.\n",
      "    \n",
      "    fitting_xdata = x[:11]\n",
      "    fitting_ydata = y[:11]\n",
      "\n",
      "    good_fit = polyfit(fitting_xdata, fitting_ydata, 1, cov=True)\n",
      "    good_params = good_fit[0]\n",
      "    good_params_cov = good_fit[1]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see the values we get for the gradient and intercept are quite different:\n",
      "\n",
      "    bad_params"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    good_params"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we visualize both fits we'll see why.\n",
      "\n",
      "    good_m = good_params[0]\n",
      "    good_c = good_params[1]\n",
      "\n",
      "    good_fitted_y = good_m*x + good_c\n",
      "\n",
      "    plot(x,y, linestyle='', marker='^')\n",
      "    plot(x, bad_fitted_y, linestyle='--', color='red', label='full fit')\n",
      "    plot(x, good_fitted_y, linestyle='--', color='green', label='partial fit')\n",
      "    legend(loc='center right')\n",
      "    \n",
      "    ylim([0,1.6])\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The partial fit matches the linear portion of the data that we are interest in whilst the full fit is skewed by the presence of the excess non linear data.\n",
      "\n",
      "To confirm that our partial fit is adequate in the range we chose we plot the residuals:\n",
      "\n",
      "    good_res = y[:11] - good_fitted_y[:11]\n",
      "    \n",
      "    plot(x, bad_res, marker='^', linestyle='', color='red', label='full_fit')\n",
      "    plot(fitting_xdata, good_res, marker='^', linestyle='', color='green', label='partial_fit')\n",
      "    plot(array([x[0],x[-1]]),array([0,0]),linestyle='--')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Weighted Fits"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus far our fitting process has assumed all the data points are equally significant. In many cases however we know that some of the measurements we have made are much more uncertain than others, we'd like to provide the fitting algorithm with this information so that when it tries to find the best gradient and intercept it cares more about the points we have greater certainty in than those we have less certainty in.\n",
      "\n",
      "Let's imagine we have some measurements of the pressure of a nobel gas in a fixed container as the temperature is increased. \n",
      "\n",
      "Lets look at the data:\n",
      "\n",
      "    gas_data = loadtxt('ideal_gas_data.txt')\n",
      "    temp = gas_data[:,0]\n",
      "    pressure = gas_data[:,1]\n",
      "\n",
      "    plot(temp, pressure, marker='^', linestyle='')\n",
      "    xlabel('T /K')\n",
      "    ylabel('p /Pa')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We believe that the nobel gas obeys the equation $pV=nRT$ where p is pressure, V volume, n the number of moles of gas, R the ideal gas constant and T is the temperature. \n",
      "\n",
      "Hence that if we plot pressure against temperature fixing n and V, we should have a straight line with gradient $nR/V$. We will use the fact that we know we have 1 mole of gas and that the volume of the box is $2.4 \\times 10^{-2} m^3$ to determine an estimate for the gas constant. \n",
      "\n",
      "We also know that the instrument we used to measure the pressure becomes less and less precise the hotter it gets. Infact let us suppose that our instrument is calibrated to perform perfect measurements at zero degrees Celsius (this is an idealization of course), but that the error associated with our measurements grows as the square of the temperature above zero degrees Celsius. We'll use the **errorbar** function to visualise our data together with the uncertainty.\n",
      "\n",
      "    std_e = (temp-273)**2\n",
      "\n",
      "    errorbar(temp, pressure, marker='^', linestyle='', yerr=std_e) \n",
      "    xlabel('T /K')\n",
      "    ylabel('p /Pa')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have set the scene let's try fitting a straight line to our data and extracting an estimate for the ideal gas constant. Treating all the points equally we get the following:\n",
      "    \n",
      "    fit_nw = polyfit(temp, pressure, 1, cov=True)\n",
      "    params_nw = fit_nw[0]\n",
      "    params_nw_cov = fit_nw[1]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    params_nw"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    params_nw_cov ** 0.5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The graphical representation is:\n",
      "\n",
      "    m_nw = params_nw[0]\n",
      "    c_nw = params_nw[1]\n",
      "\n",
      "    errorbar(temp, pressure, marker='^', linestyle='', yerr=std_e)\n",
      "    plot(temp, m_nw*temp + c_nw, linestyle='--')\n",
      "    xlabel('T /K')\n",
      "    ylabel('p /Pa')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our uncertainty for the gradient is significant and our estimate for R is poor. Now we'll fit and provide weights to tell polyfit how significant the points are. The standard way of weighting is to weight a point by the inverse of the variance, i.e. $\\frac{1}{\\sigma^2}$. This will mean the points with the largest uncertainty have the smallest weights which is what we want.\n",
      "\n",
      "    fit_w = polyfit(temp, pressure, 1, cov=True, w=1/std_e**2)\n",
      "    params_w = fit_w[0]\n",
      "    params_w_cov = fit_w[1]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    params_w"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    params_w_cov ** 0.5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that the error in the gradient has decreased significantly and our estimate for R is now much closer to the true ideal gas constant."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We plot the two fits together and note the effect of the smaller weight of the points at higher temperature on the weighted fit\n",
      "\n",
      "    m_w = params_w[0]\n",
      "    c_w = params_w[1]\n",
      "    \n",
      "    errorbar(temp, pressure, marker='^', linestyle='', yerr=std_e)\n",
      "    plot(temp, m_nw*temp + c_nw, linestyle='--', color='red', label='not weighted')\n",
      "    plot(temp, m_w*temp + c_w, linestyle='--', color='green', label='weighted')\n",
      "    legend()\n",
      "    xlabel('T /K')\n",
      "    ylabel('p /Pa')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Summary"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this workshop we covered several important data analysis methods you will use through out your degree and career.\n",
      "\n",
      "We reviewed the basic principles of storing and accessing data in arrays and how to plot that data. We looked at how a logarithmic scale can be used to visualize measurements spanning several orders of magnitude. We saw how to load data from, and save data to text files (most instruments should be able to export data in the form of text files). We have seen how simple statistical quantities of data sets can be calculated.\n",
      "\n",
      "We also looked in some detail at the important case of how to fit a linear function to a set of experimental measurements. How to extract the parameters that best describe the data and thee statistical uncertainties of those parameters (stored in the diagonal of the covarience matrix). \n",
      "\n",
      "When fitting experimental data one should always be critical and check that the fitting function reasonably describes the data. One way of doing that is to look at the plot of the residuals of the fit. When fitting data, it is common that different points have different associated uncertainties, in this case one should weight each point by the inverse of the associated variance.\n",
      "\n",
      "While linear fits are very common in many areas of chemistry, in the next workshop we will look at how to fit arbitrary non-linear functions."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Exercises"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Exercise 1"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "File [zn_flame.txt](files/zn_flame.txt) stores calibration data for an atomic absoption flame spectrophotometer. The left column corresponds to concentration of the $Zn^{2+}$ in $\\text{mg.dm}^{-3}$, and the following 4 columns correspond to absorbance readings.\n",
      "\n",
      "* Look at the content of the file, and then load the data into a variable."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Calculate the mean absorbance associated with each concentration, and create a figure containing a plot of mean absorbance against concentrations making sure to label your axes appropriately."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Calculate the standard error associate with mean absorbances and generate plot including errorbars defined by the standard error."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Do a linear fit of the concentations against mean absorbance data, taking into account the uncertainty associated with each point. Plot your fit along with the experimental data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Plot the residuals of your fit\n",
      "\n",
      "The Lambert-Beer law predicts a linear relation between concentration and absorbance. Examinethe plot you produced above and consider the residuals (bear in mind that it's hard to spot patterns if there are few data points - see exercise 2) do you think the data obeys a linear relationship?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* A river water sample passed through the spectrophotometer yielded an absorbance of 0.119. Use your linear fit to determining the concentration of $Zn^{2+}$ in this river."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exercise 2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=correlation.png></img>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In most cases in your degree you will be fitting functions to data to extract parameters given well understood theory. There are other instances where people can use fitting to try and discover relationships between variables this process is fraught with difficulties, this is particularly true if we only have a small number of data points.\n",
      "\n",
      "In this directory there is a file called 'interesting_data.txt' load the data into a variable. Fit two columns of data to a straight line and produce a plot of the original data together with your fit. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<span style=\"text-decoration:underline\" title=\"US highway Fatality Rate per 100,000 vs. &#13; Fresh Lemons imported to the US from Mexico / metric tons  &#13;  &#13;\n",
      "Source: Stephen R. Johnson; J. Chem. Inf. Model.\u00a0 2008, 48, 25-26\">Mouse over to learn what you've just plotted</span>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Look at the uncertainty reported for the coefficients and comment on the nature of relationship between the two variables - do you think our linear model is a good fit for the data?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}