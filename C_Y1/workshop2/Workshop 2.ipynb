{
 "metadata": {
  "name": "",
  "signature": "sha256:420355240e23d6b4afbc825222252f94a5ef8cfa3faee29610d6e0ecd87ef42d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# An Introduction to Plotting and Data Analysis in Python Workshop 2\n",
      "[Clyde Fare](mailto://c.fare12@imperial.ac.uk) and [Jo\u00e3o Pedro Malhado](mailto://malhado@imperial.ac.uk), Imperial College London. \n",
      "\n",
      "The notebook is licensed under a [Creative Commons Attribution 3.0 (CC-by) license](http://creativecommons.org/licenses/by/3.0/us)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Overview\n",
      "--------\n",
      "During this workshop we will recap what we covered in workshop then build on it covering construction of your own mathematical functions, the importing of modules to extend the functionality we have access to and reading and writing of data and plots. We will then learn to fit data and use basic statistics to characterise how good our fit is.\n",
      "\n",
      "This is an interactive tutorial - as you go through it any time you see something that looks like this:\n",
      "\n",
      "    a = \"Hello\"\n",
      "   \n",
      "that's followed by an empty *code cell* (a light grey rectangle with a label like *\"In[ ]\"*), you should \n",
      "type the expression in the code cell, hit Shift+Return to *execute* it, and note the output.\n",
      "\n",
      "Limit copying and pasting to cells requiring more than 5 lines! You'll learn the concepts better if you type them out yourself.\n",
      "\n",
      "Warning periodically save your work by pressing the save icon above (We'll cover the other icons later but if you want to know what they are now hover your cursor over them)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Recap from workshop 1"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Notebook"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are working inside an interactive Python Notebook. It is composed of code cells where Python code can be executed and non code cells, where descriptive material can be placed.\n",
      "\n",
      "The icons at the top of the page allow us to save the page, add new cells, cut, copy and paste cells, move cells up or down, execute the highlighted cell, halt and reset the current python kernel.\n",
      "\n",
      "We can convert a highlighted cell to a different type of cell using the dropdown menu to the immediate right of the icons.\n",
      "\n",
      "We can execute a code cell/render a markdown cell with Shift+Return.\n",
      "\n",
      "If we want to have direct access to the plotting and numerical functions and include our plots directly in the notebook we need to execute\n",
      "\n",
      "    %pylab inline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To help us visualize some of the data we will add another command that sets how many lines is to display variables\n",
      "\n",
      "    set_printoptions(linewidth=120)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Variables"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Variables, allow us to refer to data objects with names:\n",
      "    \n",
      "    x=3\n",
      "    y=array([1,2,3])\n",
      "    z=x*y\n",
      "    z"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Arrays"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Arrays are collections of numbers, that we can operate on collectively and are the containers for our data. There are special commands **linspace** and **arange** for creating arrays.\n",
      "\n",
      "**linspace** creates arrays of equally spaced numbers where we specify the initial value, the final value and how many numbers we want inbetween\n",
      "\n",
      "    linspace(-pi, pi, 10)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**arange** creates arrays of equally spaced numbers where we specify the initial value, a stop value (that will not be included), and the interval size:\n",
      "    \n",
      "    arange(0, 10, 3)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And we can refer to elements of the data in an array by using square brackets and the index of the element we want. Remembering the the first element corresponds to index zero.\n",
      "\n",
      "    arange(0,10,1)[0]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    arange(0,10,1)[5]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also refer to slices of the data using a syntax similar to arange where a colon is used in place of the comma.\n",
      "\n",
      "    my_array = arange(0,10,1)\n",
      "    my_array[0:10:3]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus the above alice takes the zeroth (first) element of my_array and then every 3rd element up to but not including 10.\n",
      "\n",
      "If the first index is omitted, it we start at the zeroth index.\n",
      "If the second index is omitted we move up to but not including the N+1th element\n",
      "If the third index is omitted the step size is 1 i.e we include all elements between the first index and the second index - 1\n",
      "\n",
      "Thus\n",
      "    my_array[::]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Arrays can be multidimensional\n",
      "\n",
      "    my_2d_array = array([[0, 3, 6, 9], [1, 4, 7, 10], [2, 5, 8, 11], [3, 6, 9, 12]])\n",
      "    my_2d_array"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Where indices now refer to the indidual rows:\n",
      "    \n",
      "    my_2d_array[1]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can apply the same indexing mechanism as we did for 1d array except we use a comma to seperate the indexing that refers to the rows and the indexing that refers to the columns:\n",
      "    \n",
      "    my_2d_array[1:4:2,0:3:2]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which is summarised by the following diagram:\n",
      "\n",
      "<img src=numpy_indexing.png></img>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can perform mathematical operations on arrays, which performs the operation on all elements of the array\n",
      "\n",
      "    sin(my_array)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Plots"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can plot using the **plot** and **scatter** commands and display using the **show** commands\n",
      "\n",
      "    plot(arange(10), arange(10)**2, label='$x^2$')\n",
      "    scatter(arange(10), arange(10)**3, label='$x^3$' )\n",
      "    title('My reminder plot')\n",
      "    xlabel('x')\n",
      "    ylabel('y')\n",
      "    legend()\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are many options\n",
      "\n",
      "    age= arange(10)\n",
      "    p_human = age**2\n",
      "    p_badger = age**3\n",
      "\n",
      "    plot(age, p_human, linewidth=2.5, linestyle=\"--\", label='Humans')\n",
      "    scatter(age, p_badger, marker='^', color='red', label='Badgers' )\n",
      "    title('My reminder plot')\n",
      "    xlabel('Age')\n",
      "    ylabel('Power')\n",
      "    legend()\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Going further"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are many occasions where we want to plot data on a logarthimic scale. To illustrate we will load some radioactivity data. Inside our data file are the half lives for some radioactive elements and their atomic numbers. If we load the data and simply plot atomic number versus half life. What we see is not very informative:\n",
      "\n",
      "    r_data = loadtxt('radioactivity_data.csv', delimiter=',')\n",
      "    atomic_nos = r_data[:,0]\n",
      "    half_lives = r_data[:,1]\n",
      "    plot(atomic_nos, half_lives)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we take a look at the half lives we can see why:\n",
      "    \n",
      "    half_lives"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that they range from $10^{-3}$ for Ununoctium to $10^{26}$ seconds for Bismuth - 29 orders of magnitude! Because of this guargantuan range of values plotting the raw data reveals almost nothing. The plot is dominated by the half life of Bismuth and none of the other variation is visible.\n",
      "\n",
      "If we scale the y-axis so that it is logarithmic i,e the units are orders of magnitude then we should have a much better way to visualize the data. We can use the **xscale** and **yscale** functions to do this.\n",
      "\n",
      "    figure(figsize=[12,8])\n",
      "    yscale('log')\n",
      "    plot(atomic_nos, half_lives, marker='o')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which allows us a much better visualization of the data.\n",
      "\n",
      "The above is equivalent to\n",
      "\n",
      "    figure(figsize=[12,8])\n",
      "    plot(atomic_nos, log(half_lives), marker='o')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A plot using logarithmic scaling for one axis and normal linear scaling for another is known as a semi-log plot. It is also possible to create a log-log plot by scaling both axis. This can be useful to pull out linear relationships in otherwise non-linear data. We will see an example of this in workshop 3."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Modules"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It would be a great pain if everytime we wanted some new functioanlity we had to build ourselves luckily there is a way to import pre-existing code in the form as modules.\n",
      "\n",
      "Inside your notebook directory you have a file called \"workshop_2_functions.py\" which contains two functions 'fibonacci' and 'factorial' which we want to use in our current notebook. There are several ways we can import and use them.\n",
      "\n",
      "We can import the whole module and call your functions from it via a dot and the name of the function we want:\n",
      "\n",
      "    import workshop_2_functions\n",
      "\n",
      "    workshop_2_functions.fibonacci(10)\n",
      "    workshop_2_functions.factorial(10)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can do the same thing but choosing to refer to your module by a different (usually shorter) name:    \n",
      "    \n",
      "    import workshop_2_functions as wrk2_f\n",
      "\n",
      "    wrk2_f.fibonacci(10)\n",
      "    wrk2_f.factorial(10)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can choose to extract one (or more) of the functions directly\n",
      "\n",
      "    from workshop_2_functions import fibonacci\n",
      "\n",
      "    fibonacci(10)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can extract all functions contained in the module\n",
      "\n",
      "    from workshop_2_functions import *\n",
      "    \n",
      "    fibonacci(10)\n",
      "    factorial(1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The downside of options 3 and particularly 4 is that you might accidentally import a function that has the same name as another variable or function being used. Option 2 is generally considered best practice.\n",
      "\n",
      "The anaconda distribution has a lot of standard scientific modules [built in](http://docs.continuum.io/anaconda/pkgs.html) these can be imported (regardless of directory) in the same way:\n",
      "\n",
      "    import numpy as np\n",
      "    np.e"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A final point to mention is that modules like numpy that are very large often further divide into sub-modules. An example is numpy's linear algebra module which is contained inside the main numpy module. We can often (but not always) use submodules from their parent module like this:\n",
      "\n",
      "    import numpy as np\n",
      "    np.linalg.norm([1, 0, 0])"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can always import and then use the submodule directly: \n",
      "\n",
      "    import numpy.linalg as la\n",
      "    la.norm([1, 0, 0])"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "or import functions from within the submodule via:\n",
      "    \n",
      "    from numpy.linalg import norm\n",
      "    norm([1, 0, 0])"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once a function is imported once in a notebook it is accessible from all the cells.\n",
      "\n",
      "    norm([1, 0, 0])"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When writing scripts we almost always put the import statements at the beginning of the file that way it's immediately clear what the code we are using depends upon.\n",
      "\n",
      "One thing to note is that we've actually been using modules all the way through. The %pylab command is really just a cheat for loading several different libraries:\n",
      "\n",
      "%pylab really does all of this!:\n",
      "\n",
      "    import numpy\n",
      "    import matplotlib\n",
      "    from matplotlib import pylab, mlab, pyplot\n",
      "    np = numpy\n",
      "    plt = pyplot\n",
      "\n",
      "    from IPython.core.pylabtools import figsize, getfigs\n",
      "\n",
      "    from pylab import *\n",
      "    from numpy import *"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Reading and Writing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The most common use case you will have when plotting data is plotting data that has been generated else where. That means you need a way to load data from somewhere into a notebook.\n",
      "\n",
      "There are severeal ways of doing this, the simplest is **loadtxt**\n",
      "\n",
      "This loads data from a text files, provided the data layed out in a regular format. If you take a look at the file [data.txt](./data.txt) which is in the same directory as this notebook. You will see each lines contains numbers separated by spaces.\n",
      "\n",
      "loadtxt will load this data into an array for us via:\n",
      "\n",
      "    our_data = loadtxt(\"data.txt\")"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    our_data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We could load a text file seperated by commas like [data2.txt](./data2.csv) via:\n",
      "    \n",
      "    loadtxt(\"data2.txt\", delimiter=',')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to loading data from files, if we have arrays of data that we want to save to file. We can use the opposite command **savetxt**. This works analagously to loadtxt thus\n",
      "    \n",
      "    savetxt('my_data_file.txt', our_data)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Creates the file my_data_file.txt, with the data values separated by spaces.\n",
      "\n",
      "If we wanted data separated by commas we would use:\n",
      "    \n",
      "    savetxt('my_data_file2.txt', our_data, delimiter=',')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take a look at the two files you've produced: [my_data_file.txt](./my_data_file.txt) and [my_data_file2.txt](./my_data_file2.txt)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Basic statistics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets load up a data set and plot a histogram of the data\n",
      "\n",
      "    d=loadtxt('d1.txt')\n",
      "    hist(d)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Histograms tell us how many many data points there are in a particular range of the data. By default the hist command creates 10 bins, equally spaced between the lowest value in the data set and the highest value in the dataset."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use the functions **min** and **max** to find the largest and smallest values in an array.\n",
      "\n",
      "    min(d)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    max(d)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Armed with these values we can check our histogram makes sense. We said before there were 10 bins by default, now that we know the maximum and minimum values we can see that the bin size must be:\n",
      "    \n",
      "    ( max(d) - min(d) )/10"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(Note we had to use brackets because we want the subtraction to occur before the division instead of)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The width of each bin is about 0.75 and we start at about -3.66 and end at about 3.8. Look at the about histogram and make sure that this makes sense - where do you expect the third bin from left to start?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can change the number of bins using the the bin keyword:\n",
      "    \n",
      "    hist(d, bins=20)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are many options to customise histograms, we won't go through them all. But this is a good point to demonstrate a way to use the built in help system. We can automatically get more information on a particular function by typing the function followed by a question mark:\n",
      "    \n",
      "    hist?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This pops up a footer window that has lots of information. It defines all the keywords and explains what form they take and what their effect is. You won't yet be able to understand everything that the helper utility tells you but it can still be a very useful resource. \n",
      "\n",
      "Another way to get the same information, is to type the function follow by the initial opening parenthesis and then simply pause a moment:\n",
      "\n",
      "    hist("
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This will create a floating pop up with the same information, you can press the plus icon in the top right of the popup to expand. If you want to reopen the pop up you can simply delete the first opening parenthesis and put it back. Try it on the line above."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading pylab gives us access to basic statistical functions like the mean:\n",
      "\n",
      "    mean(d)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The median:\n",
      "   \n",
      "   \n",
      "    median(d)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The standard deviation:\n",
      "    \n",
      "    std(d)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The percentile:\n",
      "    \n",
      "    first_q = percentile(d,25)\n",
      "    third_q = percentile(d,75)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That can be used to compute the interquartile range:\n",
      "    \n",
      "    third_q - first_q"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The standard error of the mean is a very important quantity which we will cover in further depth during the exercises. It expresses how uncertain we are in the mean value we have computed. \n",
      "\n",
      "We can calculate the standard error from the standard deviation and the square root of the number of elements.\n",
      "\n",
      "To compute the number of elements we need another built-in function **len**\n",
      "\n",
      "    no_elements = len(d)\n",
      "    std(d)/no_elements**0.5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also perform these statistical measures on 2d arrays (I.E. matrices), we'll make a 2d array using a function **randn**. This generates arrays of random numbers, to make a 5x5 array of random numbers we would use\n",
      "\n",
      "    m=randn(5,5)\n",
      "    m"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we take the mean directly we get the mean of all the numbers in the matrix, in much the same way that we would for a 1d array:\n",
      "    \n",
      "    mean(m)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However with a matrix we have the possibility to compute the means of all the columns, or all the rows individually. We do this with the axis keyword. To compute the means of the columns we would use:\n",
      "    \n",
      "    mean(m, axis=0)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This gives us an array where the first element is the mean of the first column of the 2d array, the second element is the mean of the second column of the 2d array etc."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Likewise to compute the means of the rows we would use:\n",
      "    \n",
      "    mean(m, axis=1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The same is true of the other statistical functions.\n",
      "\n",
      "    percentile(m, 25, axis=1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Filtering data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to the many ways to access the elements of an array that we covered yesterday there is a final method that is very useful. Here we access a subset of the data not by specifying the *indices* we want to include but instead by specifying their *values*. Thus we can select all elements of an array that are greater than a certain value. This is very useful to filter data in order to remove spurious values and outliers. Recalling that d is the dataset we loaded above. To select all values larger than 3 we use:\n",
      "    \n",
      "    d[d>3]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This can be combined with the statistical functions, thus to select data above the mean we would use:\n",
      "    \n",
      "    large_d = d[d>mean(d)]\n",
      "    hist(large_d)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can chain the filtering process. Thus to select the data inside the interquartile range we first select the data that is above the 25th percentile:\n",
      "    \n",
      "    q1 = percentile(d,25)\n",
      "    last_75_d = d[d>q1]\n",
      "    hist(last_75_d)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And then of that we select the data that is below the 75th percentile:\n",
      "    \n",
      "    q3 = percentile(d,75)\n",
      "    mid_d = last_75_d[last_75_d<q3]\n",
      "    hist(mid_d)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fitting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When we plot functions we do so by generating data corresponding to the function e.g. $f(x) = 3x+5$\n",
      "    \n",
      "    X = linspace(0,20)\n",
      "    f_X = 3*X+5\n",
      "    plot(X,f_X)\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case we started with a known function and generated some data using it. \n",
      "\n",
      "We often wish to do the reverse, that is start with some set of data and try and find the best function that describes it this process is called fitting. In the rest of this workshop we will focus on fitting data to straight line functions $f(x) = mx + c$. This is called *linear fitting*.\n",
      "\n",
      "To illustrate this process we will define some linear data and use **nrand** to add some random noise to simulate some experimental data:\n",
      "\n",
      "    X = linspace(0,20,100)\n",
      "    Y = 3*X+5\n",
      "    noisey_Y = Y + 10 * randn(100)\n",
      "    plot(X,Y)\n",
      "    plot(X, noisey_Y, linestyle='', marker='^')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we will try and fit the data. To do this we need to import the scipy stats module as it contains the fitting function we need. \n",
      "\n",
      "    import scipy.stats"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will use the **linregress** command from within the stats submodule to extract the slope and the intercept from the noisey data we've created.\n",
      "\n",
      "    scipy.stats.linregress(X, noisey_Y)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This command spits out 5 numbers: estimates for the slope and the intercept and 3 more numbers characterising how well a line defined by the estimated slope and intercept fits the data. The first of these three numbers is the [$R^2$](http://en.wikipedia.org/wiki/Coefficient_of_determination)  which is a number between 0 and 1 and is a measure of how good the fit is, in this case because our data has quite a bit of noise noise our $R^2$ value is only 0.86, if we had added less noise it would be closer to 1. Let's look at the fitted data. First we'll fit the model parameters to the raw data:\n",
      "\n",
      "    fitted_params = scipy.stats.linregress(X,noisey_Y)\n",
      "    m = fitted_params[0]\n",
      "    c = fitted_params[1]\n",
      "    print('Gradient = ',m)\n",
      "    print('Intercept = ',c)\n",
      "    print('R^2' = ' ,fitted_params[2])"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We've added a call to the **print** function so we can have a look at the gradient and intercept of the fitted line."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll created the fitted dataset and plot:\n",
      "\n",
      "    fitted_Y = m*X + c\n",
      "    plot(X,Y)\n",
      "    plot(X, noisey_Y, linestyle='', marker='^')\n",
      "    plot(X, fitted_Y, linestyle='--')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our fit is pretty good though it does not perfectly regenerate the function used to generate the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to $R^2$ we can get a better idea of how well our fit matches the data by computing the residuals. These are the differences between the predictions we make using our model and the actual measured data.\n",
      "\n",
      "    residuals = fitted_Y - noisey_Y"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll plot the residuals directly:\n",
      "\n",
      "    plot(X, residuals, marker='^', linestyle='')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice we see no obvious trend. If we did it would be an indicator there our model choice (in this case a straight line) is not capturing all the structure of our data. Let's see what happens if we pick a different dataset and that is not well described using a line.\n",
      "\n",
      "    Y2 = 0.5*X**2 -5*X + 50\n",
      "    noisey_Y2 = Y + 10 * randn(100)\n",
      "    plot(X,Y2)\n",
      "    plot(X, noisey_Y2, linestyle='', marker='^')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's try and fit a straight line as before:\n",
      "\n",
      "    fitted_params_2 = scipy.stats.linregress(X,noisey_Y2)\n",
      "    m = fitted_params_2[0]\n",
      "    c = fitted_params_2[1]\n",
      "\n",
      "    fitted_Y2 = m*X + c\n",
      "\n",
      "    plot(X,Y2)\n",
      "    plot(X, noisey_Y2, linestyle='', marker='^')\n",
      "    plot(X, fitted_Y2, linestyle='--')\n",
      "    show()\n",
      "\n",
      "    print('Gradient = ',m)\n",
      "    print('Intercept = ',c)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we look at the $R^2$ value:\n",
      "    \n",
      "    fitted_params[2]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that despite the above data not being linear, the $R^2$ value is very similar to the first case. (If the data was less noisy we would see a bigger difference between these two cases). Let's now plot the residuals and see what they show:\n",
      "    \n",
      "    residuals_2 = fitted_Y2 - noisey_Y2\n",
      "    plot(X, residuals_2, marker='^', linestyle='None')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see there is a definite pattern indicating our model choice is not ideal. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**skip?**\n",
      "We can also use a histogram to look at the distribution of the residuals.\n",
      "\n",
      "    hist(residuals)\n",
      "    xlim([-60,40])\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    hist(residuals_2)\n",
      "    xlim([-60,40])\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we made the x axis the same for both we can see as expected that the residuals are more broadly distributed and look less like a bell curve for the case where the model is a poorer choice. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Partial Fits"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose we have some measurements that we think should lie on a straight line, e.g. we're measuring the UV/VIS absorbance of species at different concentrations. We want to extract the gradient frmom this line. The problem is that our experimental setup means we only get the straight line behaviour for a subset of the data.\n",
      "\n",
      "Let's look at the following data:\n",
      "\n",
      "    x= arange(1.0,100,4)\n",
      "    y = array([ 0.03231454,  0.13898134,  0.2713996 ,  0.3306628 ,  0.43943964,  0.55986173,  0.65984714,  0.78631773,\n",
      "            0.89412865,  0.98014824,  1.06925855,  1.14170126,  1.20720018,  1.31978907,  1.28525302,  1.34782115,\n",
      "            1.31360386,  1.43122401,  1.40408662,  1.38122363,  1.39562417,  1.34654361,  1.42412321,  1.3962572 ,\n",
      "            1.31714601])\n",
      "    plot(x,y, marker='^', linestyle='')\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that the straight line portion of the curve is at the beginning and ends somewhere around x=40/y=1.1 i.e. the 11th data point.\n",
      "\n",
      "First we'll try applying our linear fit to the entire set of data:\n",
      "\n",
      "    bad_fit_params = scipy.stats.linregress(x,y)\n",
      "    bad_m = bad_fit_params[0]\n",
      "    bad_c = bad_fit_params[1]\n",
      "      \n",
      "    print('Gradient = ',bad_m)\n",
      "    print('Intercept = ',bad_c)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll try restricting our fit to the linear portion of the data, we first select the data we are interested in using the index then we we apply our fit to the restricted dataset.\n",
      "    \n",
      "    fitting_xdata = x[:11]\n",
      "    fitting_ydata = y[:11]\n",
      "\n",
      "    good_fit_params = scipy.stats.linregress(fitting_xdata,fitting_ydata)\n",
      "    good_m = good_fit_params[0]\n",
      "    good_c = good_fit_params[1]\n",
      "\n",
      "    print('Gradient = ',good_m)\n",
      "    print('Intercept = ',good_c)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see the values we get for the gradient and intercept are different. If we visualize both fits we'll see why. First we'll create the fitted data we're going to plot:\n",
      "\n",
      "    good_fitted_y = bad_m*x + bad_c\n",
      "    bad_fitted_y = good_m*x + good_c"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll plot it along with the original data:\n",
      "\n",
      "    plot(x,y, linestyle='', marker='^')\n",
      "    plot(x, bad_fitted_y, linestyle='--', color='red', label='full_fit')\n",
      "    plot(x, good_fitted_y, linestyle='--', color='blue', label='partial_fit')\n",
      "    legend(loc='center right')\n",
      "    \n",
      "    ylim([0,1.6])\n",
      "    show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that partial fit matches the linear portion of the data that we are interest in whilst the full fit is skewed by the presence of the excess non linear data."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Exercises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calculate and plot the residuals *for the first 11 data points* in the above data set for both the full fit and the partial fits. Can you send a trend in the residuals for the two fits?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}